{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista zadań 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI lab 2021:\n",
    "\n",
    "---\n",
    "\n",
    "**Termin wysyłki listy**: 03.06.2021 23:59 gdziekolwiek na świecie\n",
    "\n",
    "**Max punktacja** Zauważ, że jest 13 zadań, a całość listy to w sumie 78 punktów (13*6pkt=78pkt).\n",
    "\n",
    "**Jak wysyłać**\n",
    "\n",
    "Proszę wysyłajcie dwa pliki. \n",
    "\n",
    "1. Notebook z rozszerzeniem `.ipynb` z Waszymi rozwiązaniami wewnątrz. \n",
    "2. Wygenerowany plik `.html` [File/Download/HTML]. Ten plik to backup w razie gdyby były problemy z otworzeniem `.ipynb`. Opcjonalnie, możecie generować też `.pdf` i załączać go zamiast `.html`.\n",
    "\n",
    "Pliki wysyłajcie mailem na adres: lukasz.augustyniak@pwr.edu.pl. \n",
    "\n",
    "Tytuł maila wg schematu: `lista-1-numer_indeksu`. \n",
    "\n",
    "Pliki proszę nazwijcie podobnie wg schematu: `lista-1-numer_indeksu`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ważne**\n",
    "\n",
    "- Pamiętajcie uzupełnić wszystkie komórki gdzie macie informację **[ twoja odpowiedź ]**.\n",
    "- To samo dotyczy miejsc zaznaczonych jako `\"# MIEJSCE NA TWÓJ KOD\"`.\n",
    "- `\"# MIEJSCE NA TWÓJ KOD\"` może obejmować jedną lub więcej linii.\n",
    "\n",
    "**Przykład**\n",
    "\n",
    "Stwórz funkcję, która dla wartości ujemnych zwraca 0 natomiast dla liczb naturalnych zwraca ich konkretną wartość. \n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    # MIEJSCE NA TWÓJ KOD\n",
    "```\n",
    "\n",
    "A valid answer could be\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "```\n",
    "\n",
    "Another valid solution could be\n",
    "\n",
    "```python\n",
    "def threshold_func(x):\n",
    "    return max(0, x)\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Łukasz Augustyniak\n",
      "\n",
      "Last updated: 2021-04-28\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.10\n",
      "IPython version      : 7.21.0\n",
      "\n",
      "numpy     : 1.19.2\n",
      "scipy     : 1.6.1\n",
      "matplotlib: 3.3.4\n",
      "sklearn   : 0.24.1\n",
      "pandas    : 1.2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark  -d -u -a 'Łukasz Augustyniak' -v -p numpy,scipy,matplotlib,sklearn,pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Implementing a \"CART\" Decision Tree from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part of the homework, you are going to implement the CART decision tree algorithm we discussed in class. This decision tree algorithm will construct a binary decision tree based on maximizing Information Gain using the Gini Impurity measure on continuous features.\n",
    "\n",
    "\n",
    "Implementing machine learning algorithms from scratch is a very important skill, and this homework will provide exercises that will help you to develop this skill. Even if you are interested in the more theoretical aspects of machine learning, being comfortable with implementing and trying out algorithms is vital for doing research, since even the more theoretical papers in machine learning are usually accompanied by experiments or simulations to a) verify results and b) to compare algorithms with the state-of-the art.\n",
    "\n",
    "Since many students are not expert Python programmers (yet), I will provide partial solutions to the homework tasks such that you have a framework or guide to implement the solutions. Areas that you need to fill in will be marked with comments (e.g., `# YOUR CODE`). For these partial solutions, I first implemented the functions myself, and then I deleted parts you need to fill in by these comments. However, note that you can, of course, use more or fewer lines of code than I did. In other words, all that matter is that the function you write can create the same outputs as the ones I provide. How many lines of code you need to implement that function, and how efficient it is, does not matter here. The expected outputs for the respective functions will be provided for most functions so that you can double-check your solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL \n",
    "\n",
    "W pierwszej części listy zaimplementujesz algorytm drzewa decyzyjnego typu CART. Algorytm ten konstruuje binarne drzewo decyzyjne oparte na maksymalizacji Zysku Informacyjnego (ang. Information Gain) z wykorzystaniem Gini Impurity na cechach ciągłych.\n",
    "\n",
    "Implementowanie algorytmów uczenia maszynowego od podstaw jest bardzo ważną umiejętnością, a lista ta pomoże dostarczyć Ci takiej praktyki. Nawet jeśli interesują Cię bardziej teoretyczne aspekty uczenia maszynowego, umiejętność implementowania i testowania algorytmów jest niezbędna do prowadzenia badań, ponieważ nawet bardziej teoretycznym pracom na temat uczenia maszynowego zwykle towarzyszą im eksperymenty lub symulacje służące do a) weryfikacji wyników i b) porównania algorytmów z aktualnym stanem wiedzy.\n",
    "\n",
    "Ponieważ wielu studentów nie jest ekspertami w programowaniu w Pythonie (jeszcze), będę podawał częściowe rozwiązania zadań domowych, tak abyś miał ramy lub przewodnik do implementacji rozwiązań. Miejsca, które musisz uzupełnić będą oznaczone komentarzami (np. `# MIESJCE NA TWÓJ KOD`). W przypadku tych częściowych rozwiązań, najpierw sam zaimplementowałem funkcje, a następnie usunąłem fragmenty, które musisz wypełnić za pomocą tych komentarzy. Zauważ jednak, że możesz, oczywiście, użyć więcej lub mniej linii kodu niż ja to zrobiłem. Innymi słowy, wszystko, co ma znaczenie, to to, że funkcja, którą napiszesz, może tworzyć takie same dane wyjściowe jak te, które podałem. To, ile linii kodu potrzebujesz, aby zaimplementować tę funkcję i jak wydajna jest ta funkcja, nie ma tutaj znaczenia. Dla większości funkcji zostaną podane oczekiwane wyniki dla odpowiednich funkcji, abyś mógł dwukrotnie sprawdzić swoje rozwiązania. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Splitting a node / podział wierzchołka (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to implement a function that splits a dataset along a feature axis into sub-datasets. For this, we assume that the feature values are continuous (we are expecting NumPy float arrays). If the input is a NumPy integer array, we could convert it into a float array via \n",
    "\n",
    "    float_array = integer_array.astype(np.float64)\n",
    "\n",
    "To provide an intuitive example of how the splitting function should work, suppose you are given the following NumPy array with four feature values, feature values 0-3:\n",
    "\n",
    "    np.array([0.0, 1.0, 4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0])\n",
    "    \n",
    "The function you are going to implement should return a dictionary, where the dictionary key stores the information about which data point goes to the left child note and which data point goes to the right child node after applying a threshold for splitting.\n",
    "\n",
    "For example, if we were to use a `split` function on the array shown above with a theshold $t=2.5$, the split function should return the following dictionary:\n",
    "\n",
    "\n",
    "    {\n",
    "     'left': array([0, 1, 3, 4, 6, 7, 8, 9]),   # smaller than or equal to threshold\n",
    "     'right': array([2, 5])                     # larger than threshold'\n",
    "     'threshold': 2.5                           # threshold for splitting, e.g., 2.5 means <= 2.5\n",
    "     }\n",
    "     \n",
    "Note that we also store a \"threshold\" key here to keep track of what value we used for the split -- we will need this later.\n",
    "\n",
    "Now it's your turn to implement the split function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL\n",
    "\n",
    "Po pierwsze, zaimplementujemy funkcję, która dzieli zbiór danych wzdłuż osi cech na podzbiory. W tym celu zakładamy, że wartości cech są ciągłe (oczekujemy tablic zmiennoprzecinkowych NumPy). Jeśli dane wejściowe są tablicą liczb całkowitych NumPy, możemy je przekonwertować na tablicę float poprzez \n",
    "\n",
    "    float_array = integer_array.astype(np.float64)\n",
    "\n",
    "Aby zapewnić intuicyjny przykład tego, jak funkcja dzielenia powinna działać, załóżmy, że otrzymujemy następującą tablicę NumPy z czterema wartościami cech, wartościami cech 0-3:\n",
    "\n",
    "    np.array([0.0, 1.0, 4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0])\n",
    "    \n",
    "Funkcja, którą zaimplementujesz powinna zwracać słownik, w którym klucz słownika przechowuje informacje o tym, który punkt danych trafia do lewego węzła potomnego, a który do prawego węzła potomnego po zastosowaniu progu podziału.\n",
    "\n",
    "Na przykład, jeśli mielibyśmy użyć funkcji `split` na tablicy pokazanej powyżej z theshold $t=2.5$, funkcja split powinna zwrócić następujący słownik:\n",
    "\n",
    "\n",
    "    {\n",
    "     'left': array([0, 1, 3, 4, 6, 7, 8, 9]),   # mniejsza lub równa wartości progowej (threshold)\n",
    "     'right': array([2, 5])                     # większa niż threshold'\n",
    "     'threshold': 2.5                           # wartość wartości progowej (threshold'u) \n",
    "     }\n",
    "     \n",
    "Zauważ, że przechowujemy tutaj również klucz \"threshold\", aby śledzić, jakiej wartości użyliśmy do podziału - będziemy go potrzebować później.\n",
    "\n",
    "Teraz twoja kolej na zaimplementowanie funkcji dzielenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "\n",
    "\n",
    "def split(array, t):\n",
    "    \"\"\"\n",
    "    Function that splits a feature based on a threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array : NumPy array, type float, shape=(num_examples,)\n",
    "      A NumPy array containing feature values (float values).\n",
    "      \n",
    "    t : float\n",
    "      A threshold parameter for dividing the examples into\n",
    "      a left and a right child node.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    d : dictionary of the split\n",
    "      A dictionary that has 3 keys, 'left', 'right', 'threshold'.\n",
    "      The 'threshold' simply references the threshold t we provided\n",
    "      as function argument. The 'left' child node is an integer array\n",
    "      containing the indices of the examples corresponding to feature\n",
    "      values with value <= t. The 'right' child node is an integer array\n",
    "      stores the indices of the examples for which the feature value > t.\n",
    "    \"\"\"\n",
    "    # MIEJSCE NA TWÓJ KOD (prawdopodobnie będziesz musiał napisać kilak linii kodu)\n",
    "    d = {'left': left, 'right': right, 'threshold': t}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': array([0, 1, 3, 4, 6, 7, 8, 9]), 'right': array([2, 5]), 'threshold': 2.5}\n",
      "{'left': array([0, 1, 3, 4, 6, 7, 8]), 'right': array([2, 5, 9]), 'threshold': 1.5}\n",
      "{'left': array([], dtype=int64), 'right': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'threshold': -0.5}\n",
      "{'left': array([0, 1, 3, 4, 6, 7, 8]), 'right': array([2, 5, 9]), 'threshold': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "ary = np.array([0.0, 1.0, 4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0])\n",
    "\n",
    "print(split(ary, t=2.5))\n",
    "\n",
    "print(split(ary, t=1.5))\n",
    "\n",
    "print(split(ary, t=-0.5))\n",
    "\n",
    "print(split(ary, t=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2) Implement a function to compute the Gini Impurity / Zaimplementuj funkcję do obliczania Gini Impurity (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing the splitting function, the next step is to implement a criterion function so that we can compare splits on different features. I.e., we use this criterion function to decide which feature is the best feature to split for growing the decision tree at each node. Our splitting criterion will be Information Gain. However, before we implement an Information Gain function, we need to implement a function that computes the Gini Impurity at each node, which we need to compute Information Gain. For your reference, we defined Gini Impurity as follows:\n",
    "\n",
    "PL\n",
    "\n",
    "Po zaimplementowaniu funkcji podziału, następnym krokiem jest zaimplementowanie funkcji kryterium, tak abyśmy mogli porównać podziały na różne cechy, tzn. używamy funkcji kryterium, aby zdecydować, która cecha jest najlepszą cechą do podziału dla wzrostu drzewa decyzyjnego w każdym węźle. Naszym kryterium podziału będzie zysk informacyjny (Information Gain). Jednakże, zanim zaimplementujemy tę funkcję, musimy zaimplementować inną funkcję, która oblicza współczynnik Giniego (Gini Impurity / Gini coefficient) w każdym węźle, który jest nam potrzebny do obliczenia zysku informacyjnego (Information Gain). Współczynnik Giniego zdefiniujmy w następujący sposób:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$G(p) = 1 - \\sum_i (p_i)^2$$\n",
    "\n",
    "where you can think of $p_i$ as the proportion of examples with class label $i$ at a given node.\n",
    "\n",
    "gdzie o $p_i$ można myśleć jako o proporcji przykładów z etykietą klasy $i$ w danym węźle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL  (6 pts)\n",
    "\n",
    "\n",
    "def gini(array):\n",
    "    \"\"\"\n",
    "    Function that computes the Gini Impurity.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    array : NumPy array, type int, shape=(num_examples,)\n",
    "      A NumPy array containing integers representing class\n",
    "      labels.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Gini impurity (float value).\n",
    "    \n",
    "    Example\n",
    "    ----------\n",
    "    >>> gini(np.array([0, 0, 1, 1]))\n",
    "    0.5\n",
    "    \n",
    "    \"\"\"\n",
    "    # MIEJSCE NA TWÓJ KOD (prawdopodobnie będziesz musiał napisać kilak linii kodu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: To check your solution, try out the `gini` function on some example arrays. Note that the Gini impurity is maximum (0.5) if the classes are uniformly distributed; it is minimum if the array contains labels from only one single class. For reference, you may want to take a look at the plots [in L06 slide 35](https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/06_trees/06-trees__slides.pdf) in  and Figure 9 (pg. 13) in the [lecture notes for L06](https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/06_trees/06-trees__notes.pdf).\n",
    "\n",
    "PL\n",
    "\n",
    "WSKAZÓWKA: Aby sprawdzić swoje rozwiązanie, wypróbuj funkcję `gini` na kilku przykładowych tablicach. Zauważ, że Giniego Impurity jest maksymalna (0.5) jeśli klasy są równomiernie rozłożone; natoamsit jest minimalna w przypadku kiedy tablica zawiera etykiety tylko z jednej klasy. Dla odniesienia, możesz chcieć spojrzeć na wykresy [w L06 slajd 35](https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/06_trees/06-trees__slides.pdf) w i rysunek 9 (str. 13) w [notatki z wykładu dla L06](https://github.com/rasbt/stat479-machine-learning-fs19/blob/master/06_trees/06-trees__notes.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.0\n",
      "0.1653\n",
      "0.0\n",
      "0.6173\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "print(round(gini(np.array([0, 1, 0, 1, 1, 0])), 4))\n",
    "print(round(gini(np.array([1, 2])), 4))\n",
    "print(round(gini(np.array([1, 1])), 4))\n",
    "print(round(gini(np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), 4))\n",
    "print(round(gini(np.array([0, 0, 0])), 4))\n",
    "print(round(gini(np.array([1, 1, 1, 0, 1, 4, 4, 2, 1])), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3) Implement Information Gain /  Zaimplementuj Information Gain (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a working solution for the `gini` function, the next step is to compute the Information Gain. For your reference, information gain is computed as\n",
    "\n",
    "Teraz, gdy masz rozwiązanie robocze dla funkcji `gini`, następnym krokiem jest obliczenie zysku informacyjnego (Information Gain).\n",
    "\n",
    "\n",
    "$$GAIN(\\mathcal{D}, x_j) = H(\\mathcal{D}) - \\sum_{v \\in Values(x_j)} \\frac{|\\mathcal{D}_v|}{|\\mathcal{D}|} H(\\mathcal{D}_v).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "### Zauważ, że tablica x_array jest tutaj zbędna.\n",
    "### nie musisz nic robić z x_array wewnątrz funkcji\n",
    "\n",
    "\n",
    "def information_gain(x_array, y_array, split_dict):\n",
    "    \"\"\"\n",
    "    Function to compute information gain.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    \n",
    "    x_array : NumPy array, shape=(num_examples)\n",
    "      NumPy array containing the continuous feature\n",
    "      values of a given feature variable x.\n",
    "      \n",
    "    y_array : NumPy array, type int, shape=(num_examples,)\n",
    "      NumPy array containing the class labels for each\n",
    "      training example.\n",
    "      \n",
    "    split_dict : dictionary\n",
    "      A dictionary created by the `split` function, which\n",
    "      contains the indices for the left and right child node.\n",
    "      \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    Information gain for the given split in `split_dict`.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    parent_gini = # MIEJSCE NA TWÓJ KOD\n",
    "    \n",
    "    for child in ('left', 'right'):\n",
    "        \n",
    "        # TIP: freq := |D_v| / |D|\n",
    "        freq =  # MIEJSCE NA TWÓJ KOD\n",
    "        child_gini =  # MIEJSCE NA TWÓJ KOD\n",
    "        parent_gini -=  # MIEJSCE NA TWÓJ KOD\n",
    "        \n",
    "    return parent_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the following code cell for your convenience to double-check your solution. If your results don't match the results shown below, there is a bug in your implementation of the `information_gain` function.\n",
    "\n",
    "Dodałem następującą komórkę kodu dla twojej wygody, abyś mógł podwójnie sprawdzić swoje rozwiązanie. Jeśli twoje wyniki nie zgadzają się z wynikami pokazanymi poniżej, istnieje błąd w twojej implementacji funkcji `information_gain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004999999999999977\n",
      "0.003809523809523735\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "\n",
    "x_ary = np.array([0.0, 1.0, 4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0])\n",
    "y_ary = np.array([0, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
    "\n",
    "split_dict_1 = split(ary, t=2.5)\n",
    "print(information_gain(x_array=x_ary, \n",
    "                       y_array=y_ary,\n",
    "                       split_dict=split_dict_1))\n",
    "      \n",
    "split_dict_2 = split(ary, t=1.5)\n",
    "print(information_gain(x_array=x_ary, \n",
    "                       y_array=y_ary,\n",
    "                       split_dict=split_dict_2))\n",
    "\n",
    "split_dict_3 = split(ary, t=-1.5)\n",
    "print(information_gain(x_array=x_ary, \n",
    "                       y_array=y_ary,\n",
    "                       split_dict=split_dict_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4) Creating different splitting thresholds / Tworzenie różnych progów podziału (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should have almost all the main components that we need for implementing the CART decision tree algorithm: a `split` function, a `gini` function, and an `information_gain` function based on the `gini` function. However, since we are working with continuous feature variables, we need to find a good threshold $t$ on the number line of each feature, which we can use with our function `split`. \n",
    "\n",
    "\n",
    "For simplicity, we are going to implement a function that creates different thresholds based on the values found in a given feature variable. More precisely, we are going to implement a function `get_thresholds` that returns the lowest and highest feature value in a feature value array, plus the midpoint between each adjacent pairs of features (assuming the feature variable is sorted). \n",
    "\n",
    "\n",
    "For example, if a feature array consists of the values\n",
    "\n",
    "    [0.1, 1.2, 2.4, 2.5, 2.7, 3.3, 3.7]\n",
    "    \n",
    "the returned thresholds should be\n",
    "\n",
    "    [0.1, (0.1+1.2)/2, (1.2+2.4)/2, (2.4+2.5)/2, (2.5+2.7)/2, (2.7+3.3)/2, (3.3+3.7)/2, 3.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz powinniśmy mieć prawie wszystkie główne komponenty, których potrzebujemy do implementacji algorytmu drzewa decyzyjnego CART: funkcję `split`, funkcję `gini` oraz funkcję `information_gain` opartą na funkcji `gini`. Jednakże, ponieważ pracujemy z ciągłymi cechami, musimy znaleźć dobry próg $t$ na linii liczbowej każdej cechy, który możemy użyć z naszą funkcją `split`. \n",
    "\n",
    "Dla uproszczenia, zaimplementujemy funkcję, która tworzy różne progi na podstawie wartości znalezionych w danej cesze. Dokładniej, zaimplementujemy funkcję `get_thresholds`, która zwraca najniższą i najwyższą wartość cechy z tablicy wartości cech, plus punkt środkowy pomiędzy każdą sąsiadującą parą cech (zakładając, że cechy są posortowane). \n",
    "\n",
    "\n",
    "Na przykład, jeśli tablica cech składa się z wartości\n",
    "\n",
    "    [0.1, 1.2, 2.4, 2.5, 2.7, 3.3, 3.7]\n",
    "    \n",
    "zwracane progi powinny wynosić\n",
    "\n",
    "    [0.1, (0.1+1.2)/2, (1.2+2.4)/2, (2.4+2.5)/2, (2.5+2.7)/2, (2.7+3.3)/2, (3.3+3.7)/2, 3.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL  (6 pts)\n",
    "\n",
    "def get_thresholds(array):\n",
    "    \"\"\"\n",
    "    Get thresholds from a feature array.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    array : NumPy array, type float, shape=(num_examples,)\n",
    "      Array with feature values.\n",
    "      \n",
    "    Returns\n",
    "    -----------\n",
    "    NumPy float array containing thresholds.\n",
    "    \n",
    "    \"\"\"\n",
    "    # MIEJSCE NA TWÓJ KOD (prawdopodobnie będziesz musiał napisać kilak linii kodu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1  0.65 1.8  2.45 2.6  3.   3.5  3.7 ]\n",
      "[0.1  0.65 1.8  2.45 2.6  3.   3.5  3.7 ]\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "a = np.array([0.1, 1.2, 2.4, 2.5, 2.7, 3.3, 3.7])\n",
    "print(get_thresholds(a))\n",
    "\n",
    "b = np.array([3.7, 2.4, 1.2, 2.5, 3.3, 2.7, 0.1])\n",
    "print(get_thresholds(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5) Selecting the best splitting threshold / Wybieranie najlepszego progu podziału (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we implemented a function `get_thresholds` to create different splitting thresholds for a given feature. In this section, we are now implementing a function that selects the best threshold (the threshold that results in the largest information gain) from the array returned by `get_thresholds` by combining the \n",
    "\n",
    "W poprzednim rozdziale zaimplementowaliśmy funkcję `get_thresholds` do tworzenia różnych progów podziału dla danej cechy. W tej sekcji zaimplementujemy funkcję, która wybiera najlepszy próg (próg, który daje największy przyrost informacji Information Gain) z tablicy zwróconej przez `get_thresholds` poprzez kombinację progów podziału dla danej cechy. \n",
    "\n",
    "- `get_thresholds`\n",
    "- `split`\n",
    "- `information_gain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL  (6 pts)\n",
    "\n",
    "def get_best_threshold(x_array, y_array):\n",
    "    \"\"\"\n",
    "    Function to obtain the best threshold\n",
    "    based on maximizing information gain.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    x_array : NumPy array, type float, shape=(num_examples,)\n",
    "      Feature array containing the feature values of a feature\n",
    "      for each training example.\n",
    "    y_array : NumPy array, type int, shape=(num_examples,)\n",
    "      NumPy array containing the class labels for each\n",
    "      training example.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    A float representing the best threshold to split the given\n",
    "    feature variable on.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_thresholds = get_thresholds(x_array)\n",
    "    info_gains = np.zeros(all_thresholds.shape[0])\n",
    "\n",
    "    for idx, t in enumerate(all_thresholds):\n",
    "    \n",
    "        split_dict_t = # MIEJSCE NA TWÓJ KOD\n",
    "        ig = # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "        info_gains[idx] = ig\n",
    "        \n",
    "    best_idx = np.argmax(info_gains)\n",
    "    best_threshold = all_thresholds[best_idx]\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "x_ary = np.array([0.0, 1.0, 4.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0])\n",
    "y_ary = np.array([0, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
    "\n",
    "print(get_best_threshold(x_array=x_ary, \n",
    "                         y_array=y_ary))\n",
    "\n",
    "x_ary = np.array([0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 4.0, 1.0,])\n",
    "y_ary = np.array([0, 0, 1, 1, 0, 0, 0, 1, 1, 0])\n",
    "\n",
    "print(get_best_threshold(x_array=x_ary, \n",
    "                         y_array=y_ary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6) Decision Tree Splitting / Podział drzewa decyzyjnego (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to combine all the previously developed functions to recursively split a dataset on its different features to construct a decision tree that separates the examples from different classes well. We will call this function `make_tree`. \n",
    "\n",
    "For simplicity, the decision tree returned by the `make_tree` function will be represented by a Python dictionary. To illustrate this, consider the following dataset consisting of 6 training examples (class labels are 0 or 1) and 2 feature variables $X_0$ and $X_1$:\n",
    "\n",
    "```\n",
    "Inputs:\n",
    " [[0. 0.]\n",
    "  [0. 1.]\n",
    "  [1. 0.]\n",
    "  [1. 1.]\n",
    "  [2. 0.]\n",
    "  [2. 1.]]\n",
    "\n",
    "Labels:\n",
    " [0 1 0 1 1 1]\n",
    "```\n",
    " \n",
    "Based on this dataset with 6 training examples and two features, the resulting decision tree in form of the Python dictionary should look like as follows:\n",
    "\n",
    "\n",
    "\n",
    "You should return a dictionary with the following form:\n",
    "\n",
    "```\n",
    " {'X_1 <= 0.000000': {'X_0 <= 1.500000': array([0, 0]), \n",
    "                      'X_0 > 1.500000': array([1])\n",
    "                     }, \n",
    "                      \n",
    "  'X_1 > 0.000000': array([1, 1, 1])                 \n",
    " }\n",
    " ```\n",
    " \n",
    "Let me further illustrate what the different parts of the dictionary mean. Here, the `'X_1'` in `'X_1 <= 0'` refers feature 2 (the first column of the NumPy array; remember that Python starts the index at 0, in contrast to R). \n",
    "\n",
    "- 'X_1 <= 0': For training examples stored in this node where the 2nd feature is less than or equal to 0.\n",
    "- 'X_1 > 0': For training examples stored in this node where the 2nd feature is larger than 0.\n",
    "\n",
    "The \"array\" is a NumPy array that stores the class labels of the training examples at that node. In the case of `'X_1 <= 0'` we actually store actually a sub-dictionary, because this node can be split further into 2 child nodes with `'X_0 <= 1.500000'` and `'X_0 > 1.500000'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PL\n",
    "\n",
    "Następnym zadaniem jest połączenie wszystkich wcześniej opracowanych funkcji i rekurencyjnego podziału zbioru danych na różne cechy w celu skonstruowania drzewa decyzyjnego, które dobrze rozdziela przykłady z różnych klas. Funkcję tę nazwiemy `make_tree`. \n",
    "\n",
    "Dla uproszczenia, drzewo decyzyjne zwrócone przez funkcję `make_tree` będzie reprezentowane przez słownik Pythona. Aby to zilustrować, rozważmy następujący zbiór danych składający się z 6 przykładów treningowych (etykiety klas to 0 lub 1) oraz 2  cech $X_0$ i $X_1$:\n",
    "\n",
    "```\n",
    "Inputs:\n",
    " [[0. 0.]\n",
    "  [0. 1.]\n",
    "  [1. 0.]\n",
    "  [1. 1.]\n",
    "  [2. 0.]\n",
    "  [2. 1.]]\n",
    "\n",
    "Labels:\n",
    " [0 1 0 1 1 1]\n",
    "```\n",
    " \n",
    "Na podstawie tego zbioru danych z 6-cioma przykładami treningowymi i dwoma cechami, wynikowe drzewo decyzyjne w postaci słownika Pythona powinno wyglądać następująco\n",
    "\n",
    "Powinieneś zwrócić słownik o następującej postaci:\n",
    "\n",
    "```\n",
    " {'X_1 <= 0.000000': {'X_0 <= 1.500000': array([0, 0]), \n",
    "                      'X_0 > 1.500000': array([1])\n",
    "                     }, \n",
    "                      \n",
    "  'X_1 > 0.000000': array([1, 1, 1])                 \n",
    " }\n",
    " ```\n",
    " \n",
    "Pozwól mi dalej zilustrować, co oznaczają różne części słownika. Tutaj, `'X_1'` w `'X_1 <= 0'` odnosi się do cechy 2 (pierwsza kolumna tablicy NumPy; pamiętaj, że Python zaczyna indeks od 0, w przeciwieństwie do R). \n",
    "\n",
    "- 'X_1 <= 0': Dla przykładów treningowych przechowywanych w tym węźle, w których druga cecha jest mniejsza lub równa 0.\n",
    "- 'X_1 > 0': Dla przykładów treningowych przechowywanych w tym węźle, w których druga cecha jest większa od 0.\n",
    "\n",
    "\"array\" jest tablicą NumPy, która przechowuje etykiety klas przykładów treningowych w tym węźle. W przypadku `'X_1 <= 0'` przechowujemy tak naprawdę pod-słownik, ponieważ ten węzeł może być podzielony na 2 węzły dzieci z `'X_0 <= 1.500000'` i `'X_0 > 1.500000'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "def make_tree(X, y):\n",
    "    \"\"\"\n",
    "    A recursive function for building a binary decision tree.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : NumPy array, type float, shape=(num_examples, num_features)\n",
    "      A design matrix representing the feature values.\n",
    "      \n",
    "    y : NumPy array, type int, shape=(num_examples,)\n",
    "      NumPy array containing the class labels corresponding to the training examples.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Dictionary representation of the decision tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return class label array if node is empty or pure (1 example in leaf node)\n",
    "    # Zwraca tablicę etykiet klas, jeśli węzeł jest pusty lub czysty (1 przykład w węźle liście)\n",
    "    if # MIEJSCE NA TWÓJ KOD:\n",
    "        return y\n",
    "    \n",
    "    # Select the best threshold for each feature\n",
    "    # Wybierz najlepszy próg dla każdej cechy\n",
    "    thresholds = # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "    # Compute information gain for each feature based on the best threshold for each feature\n",
    "    # Oblicz zysk informacyjny dla każdej cechy w oparciu o najlepszy próg dla każdej cechy\n",
    "    \n",
    "    gains = np.zeros(X.shape[1])\n",
    "    split_dicts = []\n",
    "\n",
    "    for idx, (feature, threshold) in enumerate(zip(X.T, thresholds)):\n",
    "        split_dict = split(feature, threshold)\n",
    "        split_dicts.append(split_dict)\n",
    "        ig = information_gain(feature, y, split_dict)\n",
    "        gains[idx] = ig\n",
    "\n",
    "    # Early stopping if there is no information gain\n",
    "    # Wczesne zatrzymanie, jeśli nie ma zysku informacyjnego\n",
    "    if (gains <= 1e-05).all():\n",
    "        return y\n",
    "    \n",
    "    # Else, get best feature\n",
    "    # w przeciwnym przypadku, wybierz najlepszą cechę\n",
    "    best_feature_idx = # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    subset_dict = split_dicts[best_feature_idx]\n",
    "    \n",
    "    for node in ('left', 'right'):\n",
    "        child_y_subset = y[subset_dict[node]]\n",
    "        child_X_subset = X[subset_dict[node]]\n",
    "            \n",
    "        if node == 'left':\n",
    "            results[\"X_%d <= %f\" % (best_feature_idx, subset_dict['threshold'])] = \\\n",
    "                    make_tree(child_X_subset, child_y_subset)\n",
    "            \n",
    "        else:\n",
    "            results[\"X_%d > %f\" % (best_feature_idx, subset_dict['threshold'])] = \\\n",
    "                    make_tree(child_X_subset, child_y_subset)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the following code cell for your convenience to double-check your solution. If your results don't match the results shown below, there is a bug in your implementation of the `make_tree` function.\n",
    "\n",
    "PL\n",
    "Dodałem następującą komórkę kodu dla twojej wygody, abyś mógł podwójnie sprawdzić swoje rozwiązanie. Jeśli twoje wyniki nie pasują do tych pokazanych poniżej, to znaczy, że jest błąd w twojej implementacji funkcji `make_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " [[0. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 1.]\n",
      " [2. 0.]\n",
      " [2. 1.]]\n",
      "\n",
      "Labels:\n",
      " [0 1 0 1 1 1]\n",
      "\n",
      "Decision tree:\n",
      " {'X_1 <= 0.000000': {'X_0 <= 1.500000': array([0, 0]), 'X_0 > 1.500000': array([1])}, 'X_1 > 0.000000': array([1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "# DO NOT EDIT OR DELETE THIS CELL\n",
    "\n",
    "x1 = np.array([0., 0., 1., 1., 2., 2.])\n",
    "x2 = np.array([0., 1., 0., 1., 0., 1.])\n",
    "X = np.array( [x1, x2]).T\n",
    "y = np.array( [0,  1,  0,  1,  1,  1])\n",
    "\n",
    "print('Inputs:\\n', X)\n",
    "print('\\nLabels:\\n', y)\n",
    "\n",
    "print('\\nDecision tree:\\n', make_tree(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7) Building a Decision Tree API / Tworzenie API drzewa decyzyjnego (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step of this part of the homework is now to write an API around our decision tree code so that we can use is for making predictions. Here, we will use the common convention, established by scikit-learn, to implement the decision tree as a Python class with \n",
    "\n",
    "- a `fit` method that learns the decision tree model from a training set via the `make_tree` function we already implemented;\n",
    "- a `predict` method to predict the class labels of training examples or any unseen data points.\n",
    "\n",
    "For making predictions, since not all leaf nodes are guaranteed to be single training examples, we will use a majority voting function to predict the class label as discussed in class. I already implemented a `_traverse` method, which will recursively traverse a decision tree dictionary that is produced by the `make_tree` function.\n",
    "\n",
    "Note that for simplicity, the `predict` method will only be able to accept one data point at a time (instead of a collection of data points). Hence `x` is a vector of size $\\mathbb{R}^m$, where $m$ is the number of features. I use capital letters `X` to denote a matrix of size $\\mathbb{R}^{n\\times m}$, where $n$ is the number of training examples.\n",
    "\n",
    "PL\n",
    "\n",
    "Ostatnim krokiem w tej części listy jest napisanie API dla kodu naszego drzewa decyzyjnego, tak abyśmy mogli używać go do predykcji. W tym celu wykorzystamy wspólną konwencję, ustanowioną przez scikit-learn, aby zaimplementować drzewo decyzyjne jako klasę Pythona z \n",
    "\n",
    "- a `fit` metoda, która uczy model drzewa decyzyjnego z zestawu treningowego poprzez funkcję `make_tree`, którą już zaimplementowaliśmy;\n",
    "- a `predict` metoda do przewidywania/predykowania etykiet klas dla przykładów treningowych lub innych niewidzianych punktów danych.\n",
    "\n",
    "Nie wszystkie węzły liści są gwarantowane jako pojedyncze przykłady treningowe, więc użyjemy funkcji głosowania większościowego do przewidywania etykiety klas. Zaimplementowałem już metodę `_traverse`, która będzie rekurencyjnie przemierzać słownik drzewa decyzyjnego, który jest produkowany przez funkcję `make_tree`.\n",
    "\n",
    "Zauważ, że dla uproszczenia, metoda `predict` będzie w stanie przyjąć tylko jeden punkt danych na raz (zamiast zbioru punktów danych). Stąd `x` jest wektorem o rozmiarze $\\mathbb{R}^m$, gdzie $m$ jest liczbą cech. Używam dużych liter `X` do oznaczenia macierzy o rozmiarze $\\mathbb{R}^{n\\times m}$, gdzie $n$ jest liczbą przykładów treningowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "\n",
    "\n",
    "class CARTDecisionTreeClassifer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.splits_ = make_tree(X, y)\n",
    "        \n",
    "    def _majority_vote(self, label_array):\n",
    "        \"\"\" Returns a class label by majority voting\n",
    "            on an array label_array\n",
    "        \"\"\"\n",
    "        return # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "    def _traverse(self, x, d):\n",
    "        if isinstance(d, np.ndarray):\n",
    "            return d\n",
    "        for key in d:\n",
    "            \n",
    "            \n",
    "            if '<=' in key:\n",
    "                name, value = key.split(' <= ')\n",
    "                feature_idx = int(name.split('_')[-1])\n",
    "                value = float(value)\n",
    "                if x[feature_idx] <= value:\n",
    "                    return self._traverse(x, d[key])\n",
    "            else:\n",
    "                # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "    def predict(self, x):\n",
    "        label_array = self._traverse(x, self.splits_)\n",
    "        return self._majority_vote(label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the following code cell for your convenience to double-check your solution. If your results don't match the results shown below, there is a bug in your implementation of the `make_tree` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "tree = CARTDecisionTreeClassifer()\n",
    "tree.fit(X, y)\n",
    "\n",
    "print(tree.predict(np.array([0., 0.])))\n",
    "print(tree.predict(np.array([0., 1.])))\n",
    "print(tree.predict(np.array([1., 0.])))\n",
    "print(tree.predict(np.array([1., 0.])))\n",
    "print(tree.predict(np.array([1., 1.])))\n",
    "print(tree.predict(np.array([2., 0.])))\n",
    "print(tree.predict(np.array([2., 1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second part of this homework, you will be combining multiple decision trees to a bagging classifier. This time, we will be using the decision tree algorithm implemented in scikit-learn (which is some variant of the CART algorithm for binary splits, as implemented earlier and discussed in class).\n",
    "\n",
    "W drugiej części tej listy będziesz łączył wiele drzew decyzyjnych w klasyfikator typu Bagging. Tym razem użyjemy algorytmu drzew decyzyjnych zaimplementowanego w scikit-learn (który jest pewną odmianą algorytmu CART dla podziałów binarnych, zaimplementowanego wcześniej)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Bootrapping  (2x 6pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you remember, bagging relies on bootstrap sampling. So, as a first step, your task is to implement a function for generating bootstrap samples. In this exercise, for simplicity, we will perform the computations based on the Iris dataset.\n",
    "\n",
    "On an interesting side note, scikit-learn recently updated their version of the Iris dataset since it was discovered that the Iris version hosted on the UCI machine learning repository (https://archive.ics.uci.edu/ml/datasets/Iris/) has two data points that are different from R. Fisher's original paper (Fisher,R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950).) and changed it in their most recent version. Since most students may not have the latest scikit-learn version installed, we will be working with the Iris dataset that is deposited on UCI, which has become quite the standard in the Python machine learning community for benchmarking algorithms. Instead of manually downloading it, we will be fetching it through the `mlxtend` (http://rasbt.github.io/mlxtend/) library that you installed in the last homework.\n",
    "\n",
    "PL\n",
    "\n",
    "Jak pamiętasz, bagging opiera się na próbkowaniu bootstrapowym. Tak więc, pierwszym krokiem jest zaimplementowanie funkcji generującej próbki bootstrapowe. W tym ćwiczeniu, dla uproszczenia, obliczenia wykonamy na zbiorze danych Iris.\n",
    "\n",
    "Z ciekawostek, scikit-learn ostatnio zaktualizował swoją wersję zbioru danych Iris, ponieważ odkryto, że wersja Iris znajdująca się w repozytorium uczenia maszynowego UCI (https://archive.ics.uci.edu/ml/datasets/Iris/) ma dwa punkty danych, które różnią się od oryginalnego artykułu R. Fishera (Fisher,R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); także w \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950)) i zmienił to w swojej najnowszej wersji. Ponieważ większość studentów może nie mieć zainstalowanej najnowszej wersji scikit-learn, będziemy pracować z zestawem danych Iris, który jest zdeponowany na UCI, który stał się standardem w społeczności uczenia maszynowego w Pythonie do benchmarkowania algorytmów. Zamiast pobierać go ręcznie, będziemy go pobierać poprzez bibliotekę `mlxtend` (http://rasbt.github.io/mlxtend/), którą zainstalowałeś w ostatnim zadaniu domowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 150\n",
      "Number of features: 4\n",
      "Unique class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "from mlxtend.data import iris_data\n",
    "X, y = iris_data()\n",
    "\n",
    "print('Number of examples:', X.shape[0])\n",
    "print('Number of features:', X.shape[1])\n",
    "print('Unique class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn's `train_test_split` function to divide the dataset into a training and a test set.\n",
    "\n",
    "- The test set should contain 45 examples, and the training set should contain 105 examples.\n",
    "- To ensure reproducible results, use `123` as a random seed.\n",
    "- Perform a stratified split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyj funkcji scikit-learn `train_test_split` aby podzielić zbiór danych na trening i test.\n",
    "\n",
    "- Zestaw testowy powinien zawierać 45 przykładów, a zestaw treningowy 105 przykładów.\n",
    "- Aby zapewnić powtarzalność wyników, użyj `123` jako losowego ziarna.\n",
    "- Przeprowadzić losowanie warstwowe (ang. stratified sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    # MIEJSCE NA TWÓJ KOD\n",
    "                                                   )\n",
    "\n",
    "print('Number of training examples:', X_train.shape[0])\n",
    "print('Number of test examples:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are implementing a function to generate bootstrap samples of the training set. In particular, we will perform the bootstrapping as follows:\n",
    "\n",
    "- Create an index array with values 0, ..., 104.\n",
    "- Draw a random sample (with replacement) from this index array using the `choice` method of a NumPy `RandomState` object that is passed to the function as `rng`. \n",
    "- Select training examples from the X array and labels from the y array using the new sample of indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie zaimplementujemy funkcję generującą próbki bootstrapowe z zestawu treningowego. W szczególności, będziemy wykonywać bootstrapping w następujący sposób:\n",
    "\n",
    "- Utwórz tablicę indeksów z wartościami 0, ..., 104.\n",
    "- Wylosuj losową próbkę (z powtórzeniami) z tej tablicy indeksów używając metody `choice` obiektu NumPy `RandomState`, który jest przekazywany do funkcji jako `rng`. \n",
    "- Wybierz przykłady treningowe z tablicy `X` i etykiety z tablicy `y` używając nowej próbki indeksów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL  (6 pts)\n",
    "\n",
    "def draw_bootstrap_sample(rng, X, y):\n",
    "    sample_indices = np.arange(X.shape[0])\n",
    "    bootstrap_indices = rng.choice(\n",
    "                                    # MIEJSCE NA TWÓJ KOD\n",
    "                                    )\n",
    "    return X[bootstrap_indices], y[bootstrap_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the following code cell for your convenience to double-check your solution. If your results don't match the results shown below, there is a bug in your implementation of the `draw_bootstrap_sample` function.\n",
    "\n",
    "Dodałem następującą komórkę kodu dla twojej wygody, abyś mógł podwójnie sprawdzić swoje rozwiązanie. Jeśli Twoje wyniki nie zgadzają się z wynikami pokazanymi poniżej, istnieje błąd w Twojej implementacji funkcji `draw_bootstrap_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training inputs from bootstrap round: 105\n",
      "Number of training labels from bootstrap round: 105\n",
      "Labels:\n",
      " [0 0 1 0 0 1 2 0 2 1 0 0 2 1 1 1 1 2 1 1 2 0 2 1 2 1 1 1 0 1 0 0 1 2 0 0 0\n",
      " 0 2 1 1 2 1 2 1 1 2 1 2 0 1 1 2 2 1 0 1 0 2 2 0 1 0 2 0 0 0 0 1 2 0 0 1 0\n",
      " 1 1 0 1 1 2 2 0 2 0 2 0 1 1 2 2 0 2 2 2 0 1 0 1 2 2 2 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "rng = np.random.RandomState(123)\n",
    "X_boot, y_boot = draw_bootstrap_sample(rng, X_train, y_train)\n",
    "\n",
    "print('Number of training inputs from bootstrap round:', X_boot.shape[0])\n",
    "print('Number of training labels from bootstrap round:', y_boot.shape[0])\n",
    "print('Labels:\\n', y_boot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bagging classifier from decision trees / Klasyfikator workowy z drzew decyzyjnych (6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will implement a Bagging algorithm based on the `DecisionTreeClassifier`. I provided a partial solution for you. \n",
    "\n",
    "W tym rozdziale zaimplementujesz algorytm Bagging oparty na `DecisionTreeClassifier`. Dostarczyłem częściowe rozwiązanie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "class BaggingClassifier(object):\n",
    "    \n",
    "    def __init__(self, num_trees=10, random_state=123):\n",
    "        self.num_trees = num_trees\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.trees_ = [DecisionTreeClassifier(random_state=self.rng) for i in range(self.num_trees)]\n",
    "        for i in range(self.num_trees):\n",
    "            X_boot, y_boot = # MIEJSCE NA TWÓJ KOD w celu wylosowania próbki bootstrapowej\n",
    "            # MIEJSCE NA TWÓJ KOD aby dopasować drzewa z self.trees_ na próbkach bootstrapowych\n",
    "        \n",
    "    def predict(self, X):\n",
    "        ary = np.zeros((X.shape[0], len(self.trees_)), dtype=np.int)\n",
    "        for i in range(len(self.trees_)):\n",
    "            ary[:, i] = self.trees_[i].predict(X)\n",
    "\n",
    "        maj = np.apply_along_axis(lambda x:\n",
    "                                  np.argmax(np.bincount(x)),\n",
    "                                            axis=1,\n",
    "                                            arr=ary)\n",
    "        return maj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added the following code cell for your convenience to double-check your solution. If your results don't match the results shown below, there is a bug in your implementation of the `BaggingClassifier()`.\n",
    "\n",
    "Dodałem następującą komórkę kodu dla twojej wygody, abyś mógł podwójnie sprawdzić swoje rozwiązanie. Jeśli twoje wyniki nie pasują do wyników pokazanych poniżej, istnieje błąd w twojej implementacji `BaggingClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Tree Accuracies:\n",
      "88.9%\n",
      "93.3%\n",
      "97.8%\n",
      "93.3%\n",
      "93.3%\n",
      "93.3%\n",
      "91.1%\n",
      "97.8%\n",
      "97.8%\n",
      "97.8%\n",
      "\n",
      "Bagging Test Accuracy: 97.8%\n"
     ]
    }
   ],
   "source": [
    "# NIE EDYTUJ ANI NIE USUWAJ TEJ KOMÓRKI\n",
    "\n",
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('Individual Tree Accuracies:')\n",
    "for tree in model.trees_:\n",
    "    predictions = tree.predict(X_test) \n",
    "    print('%.1f%%' % ((predictions == y_test).sum() / X_test.shape[0] * 100))\n",
    "\n",
    "print('\\nBagging Test Accuracy: %.1f%%' % ((predictions == y_test).sum() / X_test.shape[0] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forests / Lasy losowe (3x6 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will be asked to fit a `RandomForestClassifier` on a small subset (10%) of the MNIST handwritten digits dataset (http://yann.lecun.com/exdb/mnist/). For convenience, the following code loads this small subset via mlxtend:\n",
    "\n",
    "W tym ćwiczeniu zostaniesz poproszony o wytrenowanie `RandomForestClassifier` na małych podzbiorze (10%) zbioru danych MNIST ręcznego pisma cyfr (http://yann.lecun.com/exdb/mnist/). Dla wygody, poniższy kod ładuje ten mały podzbiór poprzez mlxtend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 5000 x 784\n",
      "1st row [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n",
      " 227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n",
      " 252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n",
      " 252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n",
      " 190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n",
      "  12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n",
      "   0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n",
      "   0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n",
      " 225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n",
      " 252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n",
      " 145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.data import mnist_data\n",
    "X, y = mnist_data()\n",
    "\n",
    "print('Dimensions: %s x %s' % (X.shape[0], X.shape[1]))\n",
    "print('1st row', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell shuffles the dataset and divides it into 4500 training examples and 500 test examples, respectively.\n",
    "\n",
    "Następna komórka kodu tasuje zbiór danych i dzieli go odpowiednio na 4500 przykładów treningowych i 500 przykładów testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import shuffle_arrays_unison\n",
    "\n",
    "\n",
    "X, y = shuffle_arrays_unison((X, y), random_seed=1)\n",
    "\n",
    "X_train, y_train = X[:4500], y[:4500]\n",
    "X_test, y_test = X[4500:], y[4500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, your task is to fit a RandomForest classifier on the training set and evaluate it's predictive accuracy on the test set. \n",
    "\n",
    "Teraz Twoim zadaniem jest nauczenie klasyfikatora RandomForest na zbiorze treningowego i ocenienie jego dokładności predykcyjnej na zbiorze testowym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy {acc*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, your task is to load an image of a digit (some_digit.png) from this directory into a Python array and classify it using the random forest model. The some_digit.png image is displayed below:\n",
    "\n",
    "Następnie, Twoim zadaniem jest wczytanie obrazu cyfry (some_digit.png) z tego katalogu do tablicy Pythona i sklasyfikowanie go przy użyciu modelu random forest. Obrazek some_digit.png jest wyświetlony poniżej:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](some_digit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For loading the image, you need to install the Python imaging library PIL. Actually, Pillow, a more up-to-date fork is recommended. Execute one of the following two if you haven't installed Pillow already.\n",
    "\n",
    "Uwaga: Aby załadować obraz, musisz zainstalować bibliotekę Pythona o nazwie `PIL`. Właściwie zalecany jest Pillow, bardziej aktualny fork. Wykonaj jedną z dwóch poniższych czynności, jeśli jeszcze nie zainstalowałeś Pillow.\n",
    "\n",
    "\n",
    "- `conda install Pillow`\n",
    "\n",
    "- `pip install Pillow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I have partially pre-written the code for you.\n",
    "\n",
    "Ponownie, częściowo napisałem dla Ciebie kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_image(file_name):\n",
    "    img = Image.open(file_name)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype=np.float)\n",
    "    return data\n",
    "\n",
    "x_image = # MIEJSCE NA TWÓJ KOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT THIS CELL (6 pts)\n",
    "\n",
    "\n",
    "# The data needs to be represented as a vector (1 position for each feature)\n",
    "# Dane muszą być reprezentowane jako wektor (1 pozycja dla każdej cechy)\n",
    "x_transf = # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "# Also, scikit-learn expects 2D arrays, so we need to add a dimension\n",
    "# A także, scikit-learn oczekuje tablic 2D, więc musimy dodać wymiar\n",
    "x_transf = # MIEJSCE NA TWÓJ KOD\n",
    "\n",
    "print('Digit:', model.predict(x_transf)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
